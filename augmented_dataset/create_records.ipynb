{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import swifter # To parallelise pandas operations\n",
    "import h5py\n",
    "import sys\n",
    "sys.path.append('../../pyriodogram/')\n",
    "import ndft_features as ndft\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import collections\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFRECORDS_DIR = 'records/'\n",
    "EXAMPLES_PER_RECORD = 50000\n",
    "PLASTICC_CATEGORIES = [6, 15 ,16 ,42 ,52 ,53 ,62 ,64 ,65 ,67 ,88 ,90 ,92 ,95 ,99]\n",
    "CLASSIFIER_CATEGORIES = {cat:idx for idx, cat in enumerate(PLASTICC_CATEGORIES)}\n",
    "NUM_BANDS = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read augmented dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flux_data = pd.read_hdf('kyle_final_augment.h5', 'df')\n",
    "meta_data = pd.read_hdf('kyle_final_augment.h5', 'meta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flux_data = flux_data.astype({'object_id':float, 'mjd':float,\n",
    "                              'passband':int, 'flux': float,\n",
    "                             'flux_err':float, 'detected':int})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data = meta_data.astype({'object_id':float, 'ra':float, 'decl':float,\n",
    "                             'gal_l':float, 'gal_b':float, 'ddf':int,\n",
    "                             'hostgal_specz':float, 'hostgal_photoz':float,\n",
    "                             'hostgal_photoz_err':float,'distmod':float,\n",
    "                             'mwebv':float, 'target':int,'fold':int})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group and rename dynamic features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_arrays(df):\n",
    "    df = df.sort_values('mjd')\n",
    "    return df['mjd'].values, df['flux'].values,df['flux_err'].values, df['detected'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dynfeat = flux_data.groupby(['object_id',\n",
    "                                'passband']).apply(reduce_arrays)\n",
    "df_dynfeat = pd.DataFrame(df_dynfeat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_cols(ds):\n",
    "    mjd, flux, flux_err, detected = ds[0]\n",
    "    return pd.Series({'object_id': ds['object_id'],'passband':ds['passband'] ,\n",
    "                      'mjd': mjd, 'flux': flux, 'flux_err': flux_err,\n",
    "                    'detected': detected})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dynfeat = df_dynfeat.reset_index().swifter.apply(name_cols, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtain Fourier features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_fourier_feats(ds):\n",
    "    freqs, mag, phase, Pn, proba = ndft.extract(ds['mjd'],\n",
    "                            ds['flux'], oversampling = 4, tolerance = 1e-5)\n",
    "    ds['freqs'] = freqs\n",
    "    ds['mag'] = mag\n",
    "    ds['phase'] = phase\n",
    "    ds['period'] = Pn\n",
    "    ds['proba'] = proba\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_dynfeat = df_dynfeat.swifter.apply(extract_fourier_feats, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df_dynfeat, meta_data, on='object_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Read pickles***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-48c097cfcfaa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdf_fold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdf_fold\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/plasticc/lib/python3.6/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, join_axes, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    223\u001b[0m                        \u001b[0mkeys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m                        \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m                        copy=copy, sort=sort)\n\u001b[0m\u001b[1;32m    226\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/plasticc/lib/python3.6/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, join_axes, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No objects to concatenate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "pickle_files = glob.glob(TFRECORDS_DIR + 'fold_*')\n",
    "df = []\n",
    "for f in pickle_files:\n",
    "    df_fold = pd.read_pickle(f)\n",
    "    df += [df_fold]\n",
    "df = pd.concat(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>object_id</th>\n",
       "      <th>passband</th>\n",
       "      <th>mjd</th>\n",
       "      <th>flux</th>\n",
       "      <th>flux_err</th>\n",
       "      <th>detected</th>\n",
       "      <th>freqs</th>\n",
       "      <th>mag</th>\n",
       "      <th>phase</th>\n",
       "      <th>period</th>\n",
       "      <th>...</th>\n",
       "      <th>gal_l</th>\n",
       "      <th>gal_b</th>\n",
       "      <th>ddf</th>\n",
       "      <th>hostgal_specz</th>\n",
       "      <th>hostgal_photoz</th>\n",
       "      <th>hostgal_photoz_err</th>\n",
       "      <th>distmod</th>\n",
       "      <th>mwebv</th>\n",
       "      <th>target</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1386</th>\n",
       "      <td>1920.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[59582.3282, 59583.2409, 59584.2432, 59585.236...</td>\n",
       "      <td>[-0.39618459999999955, -3.2643575999999994, -3...</td>\n",
       "      <td>[2.872674, 2.532204, 2.558159, 2.934097, 3.362...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, ...</td>\n",
       "      <td>[0.00029251541965783417, 0.0005850308393156683...</td>\n",
       "      <td>[10.713621685288528, 33.88469008077931, 60.409...</td>\n",
       "      <td>[-1.8355565736121962, -1.327994501707416, -0.6...</td>\n",
       "      <td>[-0.09825567423829489, 1.1302372983702167, 2.5...</td>\n",
       "      <td>...</td>\n",
       "      <td>234.919132</td>\n",
       "      <td>42.24555</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3088</td>\n",
       "      <td>0.3229</td>\n",
       "      <td>0.336</td>\n",
       "      <td>41.1401</td>\n",
       "      <td>0.027</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1387</th>\n",
       "      <td>1920.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[59588.2266, 59591.2168, 59594.272, 59618.2024...</td>\n",
       "      <td>[-16.78730248888889, -16.631796488888888, -15....</td>\n",
       "      <td>[1.015543, 2.080464, 3.034246, 1.172148, 3.211...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.00029558992832890275, 0.0005911798566578055...</td>\n",
       "      <td>[111.73998679333911, 370.2667976947086, 664.91...</td>\n",
       "      <td>[-2.760655839180063, -1.7692688937666163, -0.9...</td>\n",
       "      <td>[0.5404477046253409, 2.3413844932081647, 10.15...</td>\n",
       "      <td>...</td>\n",
       "      <td>234.919132</td>\n",
       "      <td>42.24555</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3088</td>\n",
       "      <td>0.3229</td>\n",
       "      <td>0.336</td>\n",
       "      <td>41.1401</td>\n",
       "      <td>0.027</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      object_id  passband                                                mjd  \\\n",
       "1386     1920.0         0  [59582.3282, 59583.2409, 59584.2432, 59585.236...   \n",
       "1387     1920.0         1  [59588.2266, 59591.2168, 59594.272, 59618.2024...   \n",
       "\n",
       "                                                   flux  \\\n",
       "1386  [-0.39618459999999955, -3.2643575999999994, -3...   \n",
       "1387  [-16.78730248888889, -16.631796488888888, -15....   \n",
       "\n",
       "                                               flux_err  \\\n",
       "1386  [2.872674, 2.532204, 2.558159, 2.934097, 3.362...   \n",
       "1387  [1.015543, 2.080464, 3.034246, 1.172148, 3.211...   \n",
       "\n",
       "                                               detected  \\\n",
       "1386  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, ...   \n",
       "1387  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                                  freqs  \\\n",
       "1386  [0.00029251541965783417, 0.0005850308393156683...   \n",
       "1387  [0.00029558992832890275, 0.0005911798566578055...   \n",
       "\n",
       "                                                    mag  \\\n",
       "1386  [10.713621685288528, 33.88469008077931, 60.409...   \n",
       "1387  [111.73998679333911, 370.2667976947086, 664.91...   \n",
       "\n",
       "                                                  phase  \\\n",
       "1386  [-1.8355565736121962, -1.327994501707416, -0.6...   \n",
       "1387  [-2.760655839180063, -1.7692688937666163, -0.9...   \n",
       "\n",
       "                                                 period  ...        gal_l  \\\n",
       "1386  [-0.09825567423829489, 1.1302372983702167, 2.5...  ...   234.919132   \n",
       "1387  [0.5404477046253409, 2.3413844932081647, 10.15...  ...   234.919132   \n",
       "\n",
       "         gal_b  ddf  hostgal_specz  hostgal_photoz  hostgal_photoz_err  \\\n",
       "1386  42.24555    1         0.3088          0.3229               0.336   \n",
       "1387  42.24555    1         0.3088          0.3229               0.336   \n",
       "\n",
       "      distmod  mwebv  target  fold  \n",
       "1386  41.1401  0.027      90     0  \n",
       "1387  41.1401  0.027      90     0  \n",
       "\n",
       "[2 rows x 23 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write to tfrecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _int64_list_feature(values):\n",
    "    \"\"\"Returns a TF-Feature of int64_list.\n",
    "\n",
    "    Args:\n",
    "      values: A scalar or list of values.\n",
    "\n",
    "    Returns:\n",
    "      A TF-Feature.\n",
    "    \"\"\"\n",
    "    # Flat numpy array (we actually need a list)\n",
    "    if isinstance(values, np.ndarray):\n",
    "        values = np.reshape(values, [-1])\n",
    "        \n",
    "    if not isinstance(values, collections.Iterable):\n",
    "        values = [values]\n",
    "\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=values))\n",
    "\n",
    "def _float_list_feature(values):\n",
    "    \"\"\"Returns a TF-Feature of FloatList.\n",
    "\n",
    "    Args:\n",
    "      values: A scalar or list of values.\n",
    "\n",
    "    Returns:\n",
    "      A TF-Feature.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Flat numpy array (we actually need a list)\n",
    "    if isinstance(values, np.ndarray):\n",
    "        values = np.reshape(values, [-1])\n",
    "    \n",
    "    if not isinstance(values, collections.Iterable):\n",
    "        values = [values]\n",
    "\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=values))\n",
    "\n",
    "\n",
    "def _bytes_list_feature(values):\n",
    "    \"\"\"Returns a TF-Feature of bytes.\n",
    "\n",
    "    Args:\n",
    "      values: A string.\n",
    "\n",
    "    Returns:\n",
    "      A TF-Feature.\n",
    "    \"\"\"\n",
    "    def norm2bytes(value):\n",
    "        return value.encode() if isinstance(value, str) and six.PY3 else value\n",
    "    \n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[norm2bytes(values)]))\n",
    "\n",
    "def row_to_tfexample(rows):\n",
    "    \"\"\"Converts band rows for one object to tf example.\n",
    "    Args:\n",
    "      rows: data frame with object data.\n",
    "    Returns:\n",
    "      tf example.\n",
    "    \"\"\"\n",
    "    NUM_BANDS = 6\n",
    "    \n",
    "    # Timeless features\n",
    "    features = {'object/id': _float_list_feature(rows.index[0]),\n",
    "                'object/target': _int64_list_feature(CLASSIFIER_CATEGORIES[rows.iloc[0]['target']]),\n",
    "                'ddf': _int64_list_feature(rows.iloc[0]['ddf']),\n",
    "                'hostgal_specz': _float_list_feature(rows.iloc[0]['hostgal_specz']), \n",
    "                'hostgal_photoz': _float_list_feature(rows.iloc[0]['hostgal_photoz']), \n",
    "                'hostgal_photoz_err': _float_list_feature(rows.iloc[0]['hostgal_photoz_err']), \n",
    "                'distmod': _float_list_feature(rows.iloc[0]['distmod']), \n",
    "                'mwebv': _float_list_feature(rows.iloc[0]['mwebv'])}\n",
    "    \n",
    "    for band in range(NUM_BANDS):\n",
    "        row = df[df['passband'] == band].iloc[0]\n",
    "        # Time dependent features by band\n",
    "        features.update({'band_%i/num_samples'%band: _int64_list_feature(len(row['detected'])),\n",
    "                         'band_%i/detected'%band: _int64_list_feature(row['detected']),\n",
    "                         'band_%i/flux'%band: _float_list_feature(row['flux']),\n",
    "                         'band_%i/flux_err'%band: _float_list_feature(row['flux_err']),\n",
    "                         'band_%i/mjd'%band: _float_list_feature(row['mjd']),\n",
    "                         'band_%i/dft/freqs'%band: _float_list_feature(row['freqs']),\n",
    "                         'band_%i/dft/mag'%band: _float_list_feature(row['mag']),\n",
    "                         'band_%i/dft/phase'%band: _float_list_feature(row['phase']),\n",
    "                         'band_%i/dft/periodogram'%band: _float_list_feature(row['period']),\n",
    "                         'band_%i/dft/proba'%band: _float_list_feature(row['proba'])})\n",
    "    return tf.train.Example(features=tf.train.Features(feature=features))\n",
    "\n",
    "def convert_subset(df, examples_per_record, output_path, fold):\n",
    "    \"\"\"Converts fold  to tf records\n",
    "    Args:\n",
    "        df: pandas dataframe,\n",
    "        examples_per_record: number of samples saved in one tf record,\n",
    "        output_path: path to save tf records,\n",
    "        fold: cross validation fold.\n",
    "                \n",
    "    \n",
    "    \"\"\"\n",
    "    def _get_output_filename(output_path, idx, num_files):\n",
    "        if idx is None:\n",
    "            idx = 0; num_files=0;\n",
    "        return '%s-shard_%02d_of_%02d.tfrecord'%(output_path, idx, num_files)\n",
    "\n",
    "    if len(df) == 0:\n",
    "        print('-> %s fold is empty'%fold)\n",
    "        return\n",
    "    print('\\n-> Processing %s fold...'%fold)\n",
    "    # Initialize progress bar and counter\n",
    "    # Initialize tfrecord idx counter\n",
    "    if examples_per_record is None:\n",
    "        tfrecord_idx = None\n",
    "    else:\n",
    "        tfrecord_idx = 1\n",
    "    # tf writer\n",
    "    object_ids = df['object_id'].unique()\n",
    "\n",
    "    num_records = int(np.ceil(len(object_ids)/examples_per_record)) \n",
    "    print(_get_output_filename(output_path, tfrecord_idx, num_records))\n",
    "    writer = tf.python_io.TFRecordWriter(_get_output_filename(output_path, tfrecord_idx,\n",
    "                                                              num_records))\n",
    "    # Save DataFrame, just in case...\n",
    "    #df.to_pickle('%s-features.pkl'%output_path)  \n",
    "    #idx = 1\n",
    "    #progress = tf.keras.utils.Progbar(len(object_ids), interval=0.05)\n",
    "    #_ = df.groupby('object_id').progress_apply(lambda x: writer.write(row_to_tfexample(x).SerializeToString()))\n",
    "    \n",
    "    _ = df.groupby('object_id').apply(lambda x: writer.write(row_to_tfexample(x).SerializeToString()))\n",
    "\n",
    "    #df = df.set_index('object_id')\n",
    "    #for object_id in object_ids:\n",
    "        #rows = df.iat[object_id]\n",
    "        # Prepare example\n",
    "        #rows = df.iloc[i:i+6]\n",
    "        #example = row_to_tfexample(rows)\n",
    "        #writer.write(example.SerializeToString())\n",
    "        #progress.update(idx)\n",
    "        #if examples_per_record is not None and idx%examples_per_record==0:\n",
    "            # Close current writer and set a new one into a new file\n",
    "            #tfrecord_idx += 1\n",
    "            #writer.close()\n",
    "            #writer = tf.python_io.TFRecordWriter(_get_output_filename(output_path, \n",
    "                                                                      #tfrecord_idx, num_records))\n",
    "        #idx += 1\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.dirname(TFRECORDS_DIR)):\n",
    "    try:\n",
    "        os.makedirs(os.path.dirname(TFRECORDS_DIR))\n",
    "    except OSError as exc: # Guard against race condition\n",
    "        if exc.errno != errno.EEXIST:\n",
    "            raise\n",
    "\n",
    "# Save dataset descriptors\n",
    "Nfolds = df['fold'].unique()\n",
    "#for i in Nfolds: \n",
    "#    convert_subset(df[df['fold'] == i], EXAMPLES_PER_RECORD, \n",
    "#                   TFRECORDS_DIR + 'fold_%02d_of_%02d'%(i, len(Nfolds)-1), i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Parallel(n_jobs=len(Nfolds))(\n",
    "    delayed(convert_subset)(df[df['fold'] == i], EXAMPLES_PER_RECORD, \n",
    "                   TFRECORDS_DIR + 'fold_%02d_of_%02d'%(i, len(Nfolds)-1), i) for i in Nfolds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test tfrecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "records = glob.glob(TFRECORDS_DIR + 'fold_*.tfrecord')\n",
    "for example in tf.python_io.tf_record_iterator(records[0]):\n",
    "    result = tf.train.Example.FromString(example)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " metadatas = []\n",
    "for i in range(n_folds):\n",
    "    class_frequency = folds_train[i]['target'].value_counts(normalize=True)\n",
    "    plasticc_class_weights = (1/(class_frequency)).to_dict()\n",
    "    classifier_class_weights = {CLASSIFIER_CATEGORIES[k]:v for k, v in plasticc_class_weights.items()}\n",
    "    classifier_class_weights_sorted_list = [v for k, v in sorted(classifier_class_weights.items())]\n",
    "    metadatas.append({'train_objects':folds_train[i]['object_id'].tolist(),\n",
    "            'val_objects':folds_val[i]['object_id'].tolist(),\n",
    "            'train_class_weights':classifier_class_weights,\n",
    "            'train_class_weights_sorted_list':classifier_class_weights_sorted_list,\n",
    "            'train_stats':[]})#folds_train_dft_stats[i]})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
