{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import swifter # To parallelise pandas operations\n",
    "import h5py\n",
    "import sys\n",
    "sys.path.append('../../pyriodogram/')\n",
    "import ndft_features as ndft\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import collections\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFRECORDS_DIR = '../records/'\n",
    "EXAMPLES_PER_RECORD = 50000\n",
    "PLASTICC_CATEGORIES = [6, 15 ,16 ,42 ,52 ,53 ,62 ,64 ,65 ,67 ,88 ,90 ,92 ,95 ,99]\n",
    "CLASSIFIER_CATEGORIES = {cat:idx for idx, cat in enumerate(PLASTICC_CATEGORIES)}\n",
    "NUM_BANDS = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read augmented dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flux_data = pd.read_hdf('kyle_final_augment.h5', 'df')\n",
    "meta_data = pd.read_hdf('kyle_final_augment.h5', 'meta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flux_data = flux_data.astype({'object_id':float, 'mjd':float,\n",
    "                              'passband':int, 'flux': float,\n",
    "                             'flux_err':float, 'detected':int})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data = meta_data.astype({'object_id':float, 'ra':float, 'decl':float,\n",
    "                             'gal_l':float, 'gal_b':float, 'ddf':int,\n",
    "                             'hostgal_specz':float, 'hostgal_photoz':float,\n",
    "                             'hostgal_photoz_err':float,'distmod':float,\n",
    "                             'mwebv':float, 'target':int,'fold':int})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group and rename dynamic features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_arrays(df):\n",
    "    df = df.sort_values('mjd')\n",
    "    return df['mjd'].values, df['flux'].values,df['flux_err'].values, df['detected'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dynfeat = flux_data.groupby(['object_id',\n",
    "                                'passband']).apply(reduce_arrays)\n",
    "df_dynfeat = pd.DataFrame(df_dynfeat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_cols(ds):\n",
    "    mjd, flux, flux_err, detected = ds[0]\n",
    "    return pd.Series({'object_id': ds['object_id'],'passband':ds['passband'] ,\n",
    "                      'mjd': mjd, 'flux': flux, 'flux_err': flux_err,\n",
    "                    'detected': detected})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dynfeat = df_dynfeat.reset_index().swifter.apply(name_cols, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtain Fourier features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_fourier_feats(ds):\n",
    "    freqs, mag, phase, Pn, proba = ndft.extract(ds['mjd'],\n",
    "                            ds['flux'], oversampling = 4, tolerance = 1e-5)\n",
    "    ds['freqs'] = freqs\n",
    "    ds['mag'] = mag\n",
    "    ds['phase'] = phase\n",
    "    ds['period'] = Pn\n",
    "    ds['proba'] = proba\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_dynfeat = df_dynfeat.swifter.apply(extract_fourier_feats, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df_dynfeat, meta_data, on='object_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Read pickles***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_files = glob.glob(TFRECORDS_DIR + 'fold_*')\n",
    "df = []\n",
    "for f in pickle_files:\n",
    "    df_fold = pd.read_pickle(f)\n",
    "    df += [df_fold]\n",
    "df = pd.concat(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>object_id</th>\n",
       "      <th>passband</th>\n",
       "      <th>mjd</th>\n",
       "      <th>flux</th>\n",
       "      <th>flux_err</th>\n",
       "      <th>detected</th>\n",
       "      <th>freqs</th>\n",
       "      <th>mag</th>\n",
       "      <th>phase</th>\n",
       "      <th>period</th>\n",
       "      <th>...</th>\n",
       "      <th>gal_l</th>\n",
       "      <th>gal_b</th>\n",
       "      <th>ddf</th>\n",
       "      <th>hostgal_specz</th>\n",
       "      <th>hostgal_photoz</th>\n",
       "      <th>hostgal_photoz_err</th>\n",
       "      <th>distmod</th>\n",
       "      <th>mwebv</th>\n",
       "      <th>target</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1386</th>\n",
       "      <td>1920.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[59582.3282, 59583.2409, 59584.2432, 59585.236...</td>\n",
       "      <td>[-0.39618459999999955, -3.2643575999999994, -3...</td>\n",
       "      <td>[2.872674, 2.532204, 2.558159, 2.934097, 3.362...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, ...</td>\n",
       "      <td>[0.00029251541965783417, 0.0005850308393156683...</td>\n",
       "      <td>[10.713621685288528, 33.88469008077931, 60.409...</td>\n",
       "      <td>[-1.8355565736121962, -1.327994501707416, -0.6...</td>\n",
       "      <td>[-0.09825567423829489, 1.1302372983702167, 2.5...</td>\n",
       "      <td>...</td>\n",
       "      <td>234.919132</td>\n",
       "      <td>42.24555</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3088</td>\n",
       "      <td>0.3229</td>\n",
       "      <td>0.336</td>\n",
       "      <td>41.1401</td>\n",
       "      <td>0.027</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1387</th>\n",
       "      <td>1920.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[59588.2266, 59591.2168, 59594.272, 59618.2024...</td>\n",
       "      <td>[-16.78730248888889, -16.631796488888888, -15....</td>\n",
       "      <td>[1.015543, 2.080464, 3.034246, 1.172148, 3.211...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.00029558992832890275, 0.0005911798566578055...</td>\n",
       "      <td>[111.73998679333911, 370.2667976947086, 664.91...</td>\n",
       "      <td>[-2.760655839180063, -1.7692688937666163, -0.9...</td>\n",
       "      <td>[0.5404477046253409, 2.3413844932081647, 10.15...</td>\n",
       "      <td>...</td>\n",
       "      <td>234.919132</td>\n",
       "      <td>42.24555</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3088</td>\n",
       "      <td>0.3229</td>\n",
       "      <td>0.336</td>\n",
       "      <td>41.1401</td>\n",
       "      <td>0.027</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      object_id  passband                                                mjd  \\\n",
       "1386     1920.0         0  [59582.3282, 59583.2409, 59584.2432, 59585.236...   \n",
       "1387     1920.0         1  [59588.2266, 59591.2168, 59594.272, 59618.2024...   \n",
       "\n",
       "                                                   flux  \\\n",
       "1386  [-0.39618459999999955, -3.2643575999999994, -3...   \n",
       "1387  [-16.78730248888889, -16.631796488888888, -15....   \n",
       "\n",
       "                                               flux_err  \\\n",
       "1386  [2.872674, 2.532204, 2.558159, 2.934097, 3.362...   \n",
       "1387  [1.015543, 2.080464, 3.034246, 1.172148, 3.211...   \n",
       "\n",
       "                                               detected  \\\n",
       "1386  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, ...   \n",
       "1387  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                                  freqs  \\\n",
       "1386  [0.00029251541965783417, 0.0005850308393156683...   \n",
       "1387  [0.00029558992832890275, 0.0005911798566578055...   \n",
       "\n",
       "                                                    mag  \\\n",
       "1386  [10.713621685288528, 33.88469008077931, 60.409...   \n",
       "1387  [111.73998679333911, 370.2667976947086, 664.91...   \n",
       "\n",
       "                                                  phase  \\\n",
       "1386  [-1.8355565736121962, -1.327994501707416, -0.6...   \n",
       "1387  [-2.760655839180063, -1.7692688937666163, -0.9...   \n",
       "\n",
       "                                                 period  ...        gal_l  \\\n",
       "1386  [-0.09825567423829489, 1.1302372983702167, 2.5...  ...   234.919132   \n",
       "1387  [0.5404477046253409, 2.3413844932081647, 10.15...  ...   234.919132   \n",
       "\n",
       "         gal_b  ddf  hostgal_specz  hostgal_photoz  hostgal_photoz_err  \\\n",
       "1386  42.24555    1         0.3088          0.3229               0.336   \n",
       "1387  42.24555    1         0.3088          0.3229               0.336   \n",
       "\n",
       "      distmod  mwebv  target  fold  \n",
       "1386  41.1401  0.027      90     0  \n",
       "1387  41.1401  0.027      90     0  \n",
       "\n",
       "[2 rows x 23 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write to tfrecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _int64_list_feature(values):\n",
    "    \"\"\"Returns a TF-Feature of int64_list.\n",
    "\n",
    "    Args:\n",
    "      values: A scalar or list of values.\n",
    "\n",
    "    Returns:\n",
    "      A TF-Feature.\n",
    "    \"\"\"\n",
    "    # Flat numpy array (we actually need a list)\n",
    "    if isinstance(values, np.ndarray):\n",
    "        values = np.reshape(values, [-1])\n",
    "        \n",
    "    if not isinstance(values, collections.Iterable):\n",
    "        values = [values]\n",
    "\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=values))\n",
    "\n",
    "def _float_list_feature(values):\n",
    "    \"\"\"Returns a TF-Feature of FloatList.\n",
    "\n",
    "    Args:\n",
    "      values: A scalar or list of values.\n",
    "\n",
    "    Returns:\n",
    "      A TF-Feature.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Flat numpy array (we actually need a list)\n",
    "    if isinstance(values, np.ndarray):\n",
    "        values = np.reshape(values, [-1])\n",
    "    \n",
    "    if not isinstance(values, collections.Iterable):\n",
    "        values = [values]\n",
    "\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=values))\n",
    "\n",
    "\n",
    "def _bytes_list_feature(values):\n",
    "    \"\"\"Returns a TF-Feature of bytes.\n",
    "\n",
    "    Args:\n",
    "      values: A string.\n",
    "\n",
    "    Returns:\n",
    "      A TF-Feature.\n",
    "    \"\"\"\n",
    "    def norm2bytes(value):\n",
    "        return value.encode() if isinstance(value, str) and six.PY3 else value\n",
    "    \n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[norm2bytes(values)]))\n",
    "\n",
    "def row_to_tfexample(rows):\n",
    "    \"\"\"Converts band rows for one object to tf example.\n",
    "    Args:\n",
    "      rows: data frame with object data.\n",
    "    Returns:\n",
    "      tf example.\n",
    "    \"\"\"\n",
    "    NUM_BANDS = 6\n",
    "    \n",
    "    # Timeless features\n",
    "    features = {'object/id': _float_list_feature(rows.index[0]),\n",
    "                'object/target': _int64_list_feature(CLASSIFIER_CATEGORIES[rows.iloc[0]['target']]),\n",
    "                'ddf': _int64_list_feature(rows.iloc[0]['ddf']),\n",
    "                'hostgal_specz': _float_list_feature(rows.iloc[0]['hostgal_specz']), \n",
    "                'hostgal_photoz': _float_list_feature(rows.iloc[0]['hostgal_photoz']), \n",
    "                'hostgal_photoz_err': _float_list_feature(rows.iloc[0]['hostgal_photoz_err']), \n",
    "                'distmod': _float_list_feature(rows.iloc[0]['distmod']), \n",
    "                'mwebv': _float_list_feature(rows.iloc[0]['mwebv'])}\n",
    "    \n",
    "    for band in range(NUM_BANDS):\n",
    "        row = df[df['passband'] == band].iloc[0]\n",
    "        # Time dependent features by band\n",
    "        features.update({'band_%i/num_samples'%band: _int64_list_feature(len(row['detected'])),\n",
    "                         'band_%i/detected'%band: _int64_list_feature(row['detected']),\n",
    "                         'band_%i/flux'%band: _float_list_feature(row['flux']),\n",
    "                         'band_%i/flux_err'%band: _float_list_feature(row['flux_err']),\n",
    "                         'band_%i/mjd'%band: _float_list_feature(row['mjd']),\n",
    "                         'band_%i/dft/freqs'%band: _float_list_feature(row['freqs']),\n",
    "                         'band_%i/dft/mag'%band: _float_list_feature(row['mag']),\n",
    "                         'band_%i/dft/phase'%band: _float_list_feature(row['phase']),\n",
    "                         'band_%i/dft/periodogram'%band: _float_list_feature(row['period']),\n",
    "                         'band_%i/dft/proba'%band: _float_list_feature(row['proba'])})\n",
    "    return tf.train.Example(features=tf.train.Features(feature=features))\n",
    "\n",
    "def convert_subset(df, examples_per_record, output_path, fold):\n",
    "    \"\"\"Converts fold  to tf records\n",
    "    Args:\n",
    "        df: pandas dataframe,\n",
    "        examples_per_record: number of samples saved in one tf record,\n",
    "        output_path: path to save tf records,\n",
    "        fold: cross validation fold.\n",
    "                \n",
    "    \n",
    "    \"\"\"\n",
    "    def _get_output_filename(output_path, idx, num_files):\n",
    "        if idx is None:\n",
    "            idx = 0; num_files=0;\n",
    "        return '%s-shard_%02d_of_%02d.tfrecord'%(output_path, idx, num_files)\n",
    "\n",
    "    if len(df) == 0:\n",
    "        print('-> %s fold is empty'%fold)\n",
    "        return\n",
    "    print('\\n-> Processing %s fold...'%fold)\n",
    "    # Initialize progress bar and counter\n",
    "    # Initialize tfrecord idx counter\n",
    "    if examples_per_record is None:\n",
    "        tfrecord_idx = None\n",
    "    else:\n",
    "        tfrecord_idx = 1\n",
    "    # tf writer\n",
    "    object_ids = df['object_id'].unique()\n",
    "\n",
    "    num_records = int(np.ceil(len(object_ids)/examples_per_record)) \n",
    "    print(_get_output_filename(output_path, tfrecord_idx, num_records))\n",
    "    writer = tf.python_io.TFRecordWriter(_get_output_filename(output_path, tfrecord_idx,\n",
    "                                                              num_records))\n",
    "    # Save DataFrame, just in case...\n",
    "    #df.to_pickle('%s-features.pkl'%output_path)  \n",
    "    #idx = 1\n",
    "    #progress = tf.keras.utils.Progbar(len(object_ids), interval=0.05)\n",
    "    _ = df.groupby('object_id').progress_apply(lambda x: writer.write(row_to_tfexample(x).SerializeToString()))\n",
    "    \n",
    "    #_ = df.groupby('object_id').apply(lambda x: writer.write(row_to_tfexample(x).SerializeToString()))\n",
    "\n",
    "    #df = df.set_index('object_id')\n",
    "    #for object_id in object_ids:\n",
    "        #rows = df.iat[object_id]\n",
    "        # Prepare example\n",
    "        #rows = df.iloc[i:i+6]\n",
    "        #example = row_to_tfexample(rows)\n",
    "        #writer.write(example.SerializeToString())\n",
    "        #progress.update(idx)\n",
    "        #if examples_per_record is not None and idx%examples_per_record==0:\n",
    "            # Close current writer and set a new one into a new file\n",
    "            #tfrecord_idx += 1\n",
    "            #writer.close()\n",
    "            #writer = tf.python_io.TFRecordWriter(_get_output_filename(output_path, \n",
    "                                                                      #tfrecord_idx, num_records))\n",
    "        #idx += 1\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/17 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-> Processing 0 fold...\n",
      "../records/fold_00_of_04-shard_01_of_01.tfrecord\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 12%|█▏        | 2/17 [00:10<01:22,  5.49s/it]\u001b[A\n",
      " 18%|█▊        | 3/17 [00:11<00:57,  4.12s/it]\u001b[A\n",
      " 24%|██▎       | 4/17 [00:12<00:41,  3.17s/it]\u001b[A\n",
      " 29%|██▉       | 5/17 [00:13<00:30,  2.50s/it]\u001b[A\n",
      " 35%|███▌      | 6/17 [00:14<00:22,  2.03s/it]\u001b[A\n",
      " 41%|████      | 7/17 [00:15<00:17,  1.71s/it]\u001b[A\n",
      " 47%|████▋     | 8/17 [00:16<00:13,  1.48s/it]\u001b[A\n",
      " 53%|█████▎    | 9/17 [00:17<00:10,  1.33s/it]\u001b[A\n",
      " 59%|█████▉    | 10/17 [00:18<00:08,  1.22s/it]\u001b[A"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-3e698516b66c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mNfolds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     convert_subset(df_try[df_try['fold'] == i], EXAMPLES_PER_RECORD, \n\u001b[0;32m---> 13\u001b[0;31m                    TFRECORDS_DIR + 'fold_%02d_of_%02d'%(i, len(Nfolds)-1), i)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-20049c6632b7>\u001b[0m in \u001b[0;36mconvert_subset\u001b[0;34m(df, examples_per_record, output_path, fold)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;31m#idx = 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;31m#progress = tf.keras.utils.Progbar(len(object_ids), interval=0.05)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m     \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'object_id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogress_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow_to_tfexample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;31m#_ = df.groupby('object_id').apply(lambda x: writer.write(row_to_tfexample(x).SerializeToString()))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/plasticc/lib/python3.6/site-packages/tqdm/_tqdm.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(df, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    658\u001b[0m                 \u001b[0;31m# Apply the provided function (in **kwargs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m                 \u001b[0;31m# on the df using our wrapper (which provides bar updating)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 660\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m                 \u001b[0;31m# Close bar and return pandas calculation result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/plasticc/lib/python3.6/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    916\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0moption_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mode.chained_assignment'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_apply_general\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/plasticc/lib/python3.6/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m_python_apply_general\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    934\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_python_apply_general\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m         keys, values, mutated = self.grouper.apply(f, self._selected_obj,\n\u001b[0;32m--> 936\u001b[0;31m                                                    self.axis)\n\u001b[0m\u001b[1;32m    937\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m         return self._wrap_applied_output(\n",
      "\u001b[0;32m~/.conda/envs/plasticc/lib/python3.6/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, data, axis)\u001b[0m\n\u001b[1;32m   2255\u001b[0m                 hasattr(splitter, 'fast_apply') and axis == 0):\n\u001b[1;32m   2256\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2257\u001b[0;31m                 \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmutated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplitter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfast_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2258\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mgroup_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmutated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2259\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidApply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/plasticc/lib/python3.6/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36mfast_apply\u001b[0;34m(self, f, names)\u001b[0m\n\u001b[1;32m   5086\u001b[0m         \u001b[0msdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sorted_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5087\u001b[0m         results, mutated = reduction.apply_frame_axis0(sdata, f, names,\n\u001b[0;32m-> 5088\u001b[0;31m                                                        starts, ends)\n\u001b[0m\u001b[1;32m   5089\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5090\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmutated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/reduction.pyx\u001b[0m in \u001b[0;36mpandas._libs.reduction.apply_frame_axis0\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/plasticc/lib/python3.6/site-packages/tqdm/_tqdm.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    654\u001b[0m                     \u001b[0;31m# take a fast or slow code path; so stop when t.total==t.n\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 656\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m                 \u001b[0;31m# Apply the provided function (in **kwargs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-20049c6632b7>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;31m#idx = 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;31m#progress = tf.keras.utils.Progbar(len(object_ids), interval=0.05)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m     \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'object_id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogress_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow_to_tfexample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;31m#_ = df.groupby('object_id').apply(lambda x: writer.write(row_to_tfexample(x).SerializeToString()))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-20049c6632b7>\u001b[0m in \u001b[0;36mrow_to_tfexample\u001b[0;34m(rows)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mband\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_BANDS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'passband'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mband\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0;31m# Time dependent features by band\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         features.update({'band_%i/num_samples'%band: _int64_list_feature(len(row['detected'])),\n",
      "\u001b[0;32m~/.conda/envs/plasticc/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2680\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2681\u001b[0m             \u001b[0;31m# either boolean or fancy integer index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2682\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2683\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2684\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/plasticc/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2722\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2723\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2724\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2725\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2726\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/plasticc/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_take\u001b[0;34m(self, indices, axis, is_copy)\u001b[0m\n\u001b[1;32m   2787\u001b[0m         new_data = self._data.take(indices,\n\u001b[1;32m   2788\u001b[0m                                    \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_block_manager_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2789\u001b[0;31m                                    verify=True)\n\u001b[0m\u001b[1;32m   2790\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2791\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/plasticc/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, indexer, axis, verify, convert)\u001b[0m\n\u001b[1;32m   4537\u001b[0m         \u001b[0mnew_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4538\u001b[0m         return self.reindex_indexer(new_axis=new_labels, indexer=indexer,\n\u001b[0;32m-> 4539\u001b[0;31m                                     axis=axis, allow_dups=True)\n\u001b[0m\u001b[1;32m   4540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4541\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlsuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrsuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/plasticc/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mreindex_indexer\u001b[0;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy)\u001b[0m\n\u001b[1;32m   4423\u001b[0m             new_blocks = [blk.take_nd(indexer, axis=axis, fill_tuple=(\n\u001b[1;32m   4424\u001b[0m                 fill_value if fill_value is not None else blk.fill_value,))\n\u001b[0;32m-> 4425\u001b[0;31m                 for blk in self.blocks]\n\u001b[0m\u001b[1;32m   4426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4427\u001b[0m         \u001b[0mnew_axes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/plasticc/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   4423\u001b[0m             new_blocks = [blk.take_nd(indexer, axis=axis, fill_tuple=(\n\u001b[1;32m   4424\u001b[0m                 fill_value if fill_value is not None else blk.fill_value,))\n\u001b[0;32m-> 4425\u001b[0;31m                 for blk in self.blocks]\n\u001b[0m\u001b[1;32m   4426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4427\u001b[0m         \u001b[0mnew_axes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/plasticc/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mtake_nd\u001b[0;34m(self, indexer, axis, new_mgr_locs, fill_tuple)\u001b[0m\n\u001b[1;32m   1256\u001b[0m             \u001b[0mfill_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfill_tuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1257\u001b[0m             new_values = algos.take_nd(values, indexer, axis=axis,\n\u001b[0;32m-> 1258\u001b[0;31m                                        allow_fill=True, fill_value=fill_value)\n\u001b[0m\u001b[1;32m   1259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1260\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_mgr_locs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/plasticc/lib/python3.6/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36mtake_nd\u001b[0;34m(arr, indexer, axis, out, fill_value, mask_info, allow_fill)\u001b[0m\n\u001b[1;32m   1657\u001b[0m     func = _get_take_nd_function(arr.ndim, arr.dtype, out.dtype, axis=axis,\n\u001b[1;32m   1658\u001b[0m                                  mask_info=mask_info)\n\u001b[0;32m-> 1659\u001b[0;31m     \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1661\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mflip_order\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if not os.path.exists(os.path.dirname(TFRECORDS_DIR)):\n",
    "    try:\n",
    "        os.makedirs(os.path.dirname(TFRECORDS_DIR))\n",
    "    except OSError as exc: # Guard against race condition\n",
    "        if exc.errno != errno.EEXIST:\n",
    "            raise\n",
    "\n",
    "# Save dataset descriptors\n",
    "Nfolds = df['fold'].unique()\n",
    "df_try = df[:100]\n",
    "for i in Nfolds: \n",
    "    convert_subset(df_try[df_try['fold'] == i], EXAMPLES_PER_RECORD, \n",
    "                   TFRECORDS_DIR + 'fold_%02d_of_%02d'%(i, len(Nfolds)-1), i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Parallel(n_jobs=len(Nfolds))(delayed(convert_subset)(df_try[df_try['fold'] == i], EXAMPLES_PER_RECORD, \n",
    "                   TFRECORDS_DIR + 'fold_%02d_of_%02d'%(i, len(Nfolds)-1), i) for i in Nfolds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test tfrecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "records = glob.glob(TFRECORDS_DIR + 'fold_*.tfrecord')\n",
    "for example in tf.python_io.tf_record_iterator(records[0]):\n",
    "    result = tf.train.Example.FromString(example)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " metadatas = []\n",
    "for i in range(n_folds):\n",
    "    class_frequency = folds_train[i]['target'].value_counts(normalize=True)\n",
    "    plasticc_class_weights = (1/(class_frequency)).to_dict()\n",
    "    classifier_class_weights = {CLASSIFIER_CATEGORIES[k]:v for k, v in plasticc_class_weights.items()}\n",
    "    classifier_class_weights_sorted_list = [v for k, v in sorted(classifier_class_weights.items())]\n",
    "    metadatas.append({'train_objects':folds_train[i]['object_id'].tolist(),\n",
    "            'val_objects':folds_val[i]['object_id'].tolist(),\n",
    "            'train_class_weights':classifier_class_weights,\n",
    "            'train_class_weights_sorted_list':classifier_class_weights_sorted_list,\n",
    "            'train_stats':[]})#folds_train_dft_stats[i]})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
